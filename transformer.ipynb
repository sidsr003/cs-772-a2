{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpMXMn8FeG-8",
        "outputId": "3d1f65a8-1fb6-4aad-8d45-2297481936f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "yes\n"
          ]
        }
      ],
      "source": [
        "print(\"yes\")"
      ],
      "id": "FpMXMn8FeG-8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3mSoLp_eG--"
      },
      "source": [
        "## Imports & Global Constants"
      ],
      "id": "X3mSoLp_eG--"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lHJYV7nreG--"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Optional, Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "try:\n",
        "    from datasets import load_dataset\n",
        "except ImportError:\n",
        "    load_dataset = None\n",
        "try:\n",
        "    from huggingface_hub import hf_hub_download\n",
        "except ImportError:\n",
        "    hf_hub_download = None\n",
        "\n",
        "PAD_TOKEN = \"<pad>\"\n",
        "SOS_TOKEN = \"<sos>\"\n",
        "EOS_TOKEN = \"<eos>\"\n",
        "UNK_TOKEN = \"<unk>\"\n",
        "SPECIAL_TOKENS = [PAD_TOKEN, SOS_TOKEN, EOS_TOKEN, UNK_TOKEN]\n",
        "MAX_TRAIN_LIMIT = 100_000\n"
      ],
      "id": "lHJYV7nreG--"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAX1dqSReG--"
      },
      "source": [
        "## Vocabulary Utilities"
      ],
      "id": "rAX1dqSReG--"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DI7LQSwzeG--"
      },
      "outputs": [],
      "source": [
        "class CharVocab:\n",
        "    def __init__(self, tokens: Optional[List[str]] = None, min_freq: int = 1):\n",
        "        self.min_freq = min_freq\n",
        "        self.token2idx: Dict[str, int] = {}\n",
        "        self.idx2token: List[str] = []\n",
        "        if tokens:\n",
        "            self.build(tokens)\n",
        "\n",
        "    def build(self, tokens: List[str]) -> None:\n",
        "        freq: Dict[str, int] = {}\n",
        "        for token in tokens:\n",
        "            freq[token] = freq.get(token, 0) + 1\n",
        "        self.idx2token = list(SPECIAL_TOKENS)\n",
        "        for ch in sorted([c for c, f in freq.items() if f >= self.min_freq]):\n",
        "            if ch in SPECIAL_TOKENS:\n",
        "                continue\n",
        "            self.idx2token.append(ch)\n",
        "        self.token2idx = {t: i for i, t in enumerate(self.idx2token)}\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.idx2token)\n",
        "\n",
        "    def encode(self, text: str) -> List[int]:\n",
        "        return [self.token2idx.get(ch, self.token2idx[UNK_TOKEN]) for ch in text]\n",
        "\n",
        "    def decode(self, ids: List[int]) -> str:\n",
        "        out: List[str] = []\n",
        "        for idx in ids:\n",
        "            if idx < 0 or idx >= len(self.idx2token):\n",
        "                out.append(UNK_TOKEN)\n",
        "            else:\n",
        "                out.append(self.idx2token[idx])\n",
        "        return \"\".join(out)\n",
        "\n",
        "    @property\n",
        "    def pad_idx(self) -> int:\n",
        "        return self.token2idx[PAD_TOKEN]\n",
        "\n",
        "    @property\n",
        "    def sos_idx(self) -> int:\n",
        "        return self.token2idx[SOS_TOKEN]\n",
        "\n",
        "    @property\n",
        "    def eos_idx(self) -> int:\n",
        "        return self.token2idx[EOS_TOKEN]\n",
        "\n",
        "    @property\n",
        "    def unk_idx(self) -> int:\n",
        "        return self.token2idx[UNK_TOKEN]"
      ],
      "id": "DI7LQSwzeG--"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anddEU_jeG-_"
      },
      "source": [
        "## Dataset Wrappers & Collate Function"
      ],
      "id": "anddEU_jeG-_"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fGBwTPpoeG_A"
      },
      "outputs": [],
      "source": [
        "class TransliterationDataset(Dataset):\n",
        "    def __init__(self, records: List[Tuple[str, str]]):\n",
        "        self.records = records\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.records)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Tuple[str, str]:\n",
        "        return self.records[idx]\n",
        "\n",
        "\n",
        "def collate_fn(batch, src_vocab: CharVocab, tgt_vocab: CharVocab, device: torch.device):\n",
        "    src_seqs = [s for s, _ in batch]\n",
        "    tgt_seqs = [t for _, t in batch]\n",
        "\n",
        "    src_idxs = [src_vocab.encode(s) for s in src_seqs]\n",
        "    tgt_in_idxs = [[tgt_vocab.sos_idx] + tgt_vocab.encode(t) for t in tgt_seqs]\n",
        "    tgt_out_idxs = [tgt_vocab.encode(t) + [tgt_vocab.eos_idx] for t in tgt_seqs]\n",
        "\n",
        "    src_lengths = [len(x) for x in src_idxs]\n",
        "    tgt_lengths = [len(x) for x in tgt_out_idxs]\n",
        "\n",
        "    max_src = max(src_lengths)\n",
        "    max_tgt = max(tgt_lengths)\n",
        "\n",
        "    src_padded = torch.full((len(batch), max_src), src_vocab.pad_idx, dtype=torch.long)\n",
        "    for i, seq in enumerate(src_idxs):\n",
        "        src_padded[i, : len(seq)] = torch.tensor(seq, dtype=torch.long)\n",
        "\n",
        "    tgt_in_padded = torch.full((len(batch), max_tgt), tgt_vocab.pad_idx, dtype=torch.long)\n",
        "    tgt_out_padded = torch.full((len(batch), max_tgt), tgt_vocab.pad_idx, dtype=torch.long)\n",
        "    for i, (tin, tout) in enumerate(zip(tgt_in_idxs, tgt_out_idxs)):\n",
        "        tgt_in_padded[i, : len(tin)] = torch.tensor(tin, dtype=torch.long)\n",
        "        tgt_out_padded[i, : len(tout)] = torch.tensor(tout, dtype=torch.long)\n",
        "\n",
        "    return (\n",
        "        src_padded.to(device),\n",
        "        torch.tensor(src_lengths, dtype=torch.long, device=device),\n",
        "        tgt_in_padded.to(device),\n",
        "        tgt_out_padded.to(device),\n",
        "        torch.tensor(tgt_lengths, dtype=torch.long, device=device),\n",
        "    )"
      ],
      "id": "fGBwTPpoeG_A"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJ0UlHsjeG_C"
      },
      "source": [
        "## Positional Encoding Module"
      ],
      "id": "xJ0UlHsjeG_C"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "28UJLyofeG_E"
      },
      "outputs": [],
      "source": [
        "# ========================================\n",
        "# Configuration Class\n",
        "# Add this cell BEFORE LocalTransformer\n",
        "# ========================================\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from typing import Optional\n",
        "\n",
        "@dataclass\n",
        "class TransformerConfig:\n",
        "    d_model: int = 256\n",
        "    nhead: int = 4\n",
        "    num_encoder_layers: int = 2\n",
        "    num_decoder_layers: int = 2\n",
        "    dim_feedforward: int = 512\n",
        "    dropout: float = 0.1\n",
        "    local_window: Optional[int] = None\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model: int, dropout: float = 0.1, maxlen: int = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        position = torch.arange(0, maxlen, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(maxlen, d_model)\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        if d_model % 2 == 1:\n",
        "            pe[:, 1::2] = torch.cos(position * div_term[:-1])\n",
        "        else:\n",
        "            pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer(\"pe\", pe.unsqueeze(0))\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = x + self.pe[:, :x.size(1), :]\n",
        "        return self.dropout(x)\n",
        "\n",
        "\n",
        "class LocalTransformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size: int, tgt_vocab_size: int, config: TransformerConfig, device: torch.device):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.device = device\n",
        "\n",
        "        self.src_tok_emb = nn.Embedding(src_vocab_size, config.d_model, padding_idx=0)\n",
        "        self.tgt_tok_emb = nn.Embedding(tgt_vocab_size, config.d_model, padding_idx=0)\n",
        "        self.pos_encoder = PositionalEncoding(config.d_model, dropout=config.dropout)\n",
        "        self.pos_decoder = PositionalEncoding(config.d_model, dropout=config.dropout)\n",
        "\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=config.d_model,\n",
        "            nhead=config.nhead,\n",
        "            dim_feedforward=config.dim_feedforward,\n",
        "            dropout=config.dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "        decoder_layer = nn.TransformerDecoderLayer(\n",
        "            d_model=config.d_model,\n",
        "            nhead=config.nhead,\n",
        "            dim_feedforward=config.dim_feedforward,\n",
        "            dropout=config.dropout,\n",
        "            batch_first=True,\n",
        "        )\n",
        "\n",
        "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=config.num_encoder_layers)\n",
        "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=config.num_decoder_layers)\n",
        "        self.generator = nn.Linear(config.d_model, tgt_vocab_size)\n",
        "\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        for name, p in self.named_parameters():\n",
        "            if 'weight' in name and p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p, gain=1.0)\n",
        "            elif 'bias' in name:\n",
        "                nn.init.zeros_(p)\n",
        "\n",
        "    def build_encoder_mask(self, seq_len: int, device: torch.device) -> Optional[torch.Tensor]:\n",
        "        window = self.config.local_window\n",
        "\n",
        "        # Use full attention if window is None or too large\n",
        "        if window is None or window <= 0 or window >= seq_len:\n",
        "            return None\n",
        "\n",
        "        # Build mask: 0.0 = can attend, -inf = cannot attend\n",
        "        mask = torch.full((seq_len, seq_len), float('-inf'), device=device, dtype=torch.float32)\n",
        "\n",
        "        for i in range(seq_len):\n",
        "            start = max(0, i - window)\n",
        "            end = min(seq_len, i + window + 1)\n",
        "            mask[i, start:end] = 0.0  # Allow attention in window\n",
        "\n",
        "        return mask\n",
        "\n",
        "    def build_decoder_mask(self, seq_len: int, device: torch.device) -> torch.Tensor:\n",
        "        window = self.config.local_window\n",
        "\n",
        "        # Causal mask (upper triangular with -inf)\n",
        "        mask = torch.triu(torch.full((seq_len, seq_len), float('-inf'),\n",
        "                                     device=device, dtype=torch.float32), diagonal=1)\n",
        "\n",
        "        # Add local window constraint\n",
        "        if window is not None and window > 0 and window < seq_len:\n",
        "            for i in range(seq_len):\n",
        "                start = max(0, i - window)\n",
        "                if start > 0:\n",
        "                    mask[i, :start] = float('-inf')\n",
        "\n",
        "        return mask\n",
        "\n",
        "    def forward(self, src, tgt_in, src_key_padding_mask, tgt_key_padding_mask):\n",
        "        # Embed and scale\n",
        "        src_emb = self.src_tok_emb(src) * math.sqrt(self.config.d_model)\n",
        "        tgt_emb = self.tgt_tok_emb(tgt_in) * math.sqrt(self.config.d_model)\n",
        "\n",
        "        # Add positional encoding\n",
        "        src_emb = self.pos_encoder(src_emb)\n",
        "        tgt_emb = self.pos_decoder(tgt_emb)\n",
        "\n",
        "        # Build masks\n",
        "        src_mask = self.build_encoder_mask(src_emb.size(1), src_emb.device)\n",
        "        tgt_mask = self.build_decoder_mask(tgt_emb.size(1), tgt_emb.device)\n",
        "\n",
        "        # Encode\n",
        "        memory = self.encoder(\n",
        "            src_emb,\n",
        "            mask=src_mask,\n",
        "            src_key_padding_mask=src_key_padding_mask\n",
        "        )\n",
        "\n",
        "        if torch.isnan(memory).any():\n",
        "            print(\"WARNING: NaN in encoder output\")\n",
        "\n",
        "        # Decode\n",
        "        out = self.decoder(\n",
        "            tgt_emb,\n",
        "            memory,\n",
        "            tgt_mask=tgt_mask,\n",
        "            tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "            memory_key_padding_mask=src_key_padding_mask,\n",
        "        )\n",
        "\n",
        "        return self.generator(out)\n",
        "\n",
        "    def encode(self, src, src_key_padding_mask):\n",
        "        src_emb = self.src_tok_emb(src) * math.sqrt(self.config.d_model)\n",
        "        src_emb = self.pos_encoder(src_emb)\n",
        "        src_mask = self.build_encoder_mask(src_emb.size(1), src_emb.device)\n",
        "        return self.encoder(src_emb, mask=src_mask, src_key_padding_mask=src_key_padding_mask)\n",
        "\n",
        "    def decode(self, tgt, memory, src_key_padding_mask, tgt_key_padding_mask):\n",
        "        tgt_emb = self.tgt_tok_emb(tgt) * math.sqrt(self.config.d_model)\n",
        "        tgt_emb = self.pos_decoder(tgt_emb)\n",
        "        tgt_mask = self.build_decoder_mask(tgt_emb.size(1), tgt_emb.device)\n",
        "        out = self.decoder(\n",
        "            tgt_emb,\n",
        "            memory,\n",
        "            tgt_mask=tgt_mask,\n",
        "            tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "            memory_key_padding_mask=src_key_padding_mask,\n",
        "        )\n",
        "        return self.generator(out)"
      ],
      "id": "28UJLyofeG_E"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85_fJx9TeG_F"
      },
      "source": [
        "## Transformer Configuration & Model"
      ],
      "id": "85_fJx9TeG_F"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5Scq5o7eG_H"
      },
      "source": [
        "## Data Loading Helpers"
      ],
      "id": "R5Scq5o7eG_H"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oUM36gNdeG_H"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json, os, re, random, zipfile, shutil, tempfile\n",
        "from typing import List, Tuple, Optional\n",
        "from huggingface_hub import hf_hub_download, list_repo_files\n",
        "\n",
        "\n",
        "def read_jsonl(path: str) -> List[Tuple[str, str]]:\n",
        "    \"\"\"Read Aksharantar-style JSONL into (native, english) tuples.\"\"\"\n",
        "    records: List[Tuple[str, str]] = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            obj = json.loads(line)\n",
        "            src = (obj.get(\"native word\") or obj.get(\"native_word\") or obj.get(\"native\") or \"\").strip()\n",
        "            tgt = (obj.get(\"english word\") or obj.get(\"english_word\") or obj.get(\"english\") or \"\").strip().lower()\n",
        "            if src and tgt:\n",
        "                records.append((src, tgt))\n",
        "    return records\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ---------- Local file helper ----------\n",
        "\n",
        "_SPLIT_MAP = {\n",
        "    \"train\": \"train\",\n",
        "    \"training\": \"train\",\n",
        "    \"validation\": \"valid\",\n",
        "    \"val\": \"valid\",\n",
        "    \"dev\": \"valid\",\n",
        "    \"test\": \"test\",\n",
        "}\n",
        "\n",
        "def _resolve_local_file(base_dir: str, language: str, split: str) -> Optional[str]:\n",
        "    \"\"\"Find {lang}_{split}.{jsonl|json} in base_dir; return path or None.\"\"\"\n",
        "    target = _SPLIT_MAP.get(split.lower(), split.lower())\n",
        "    candidates = [\n",
        "        f\"{language}_{target}.jsonl\",\n",
        "        f\"{language}_{target}.json\",\n",
        "    ]\n",
        "    for name in candidates:\n",
        "        p = os.path.join(base_dir, name)\n",
        "        if os.path.isfile(p):\n",
        "            return p\n",
        "    return None\n",
        "\n",
        "\n",
        "import json, os, re, random\n",
        "from typing import List, Tuple, Optional\n",
        "\n",
        "BAD_BACKSLASH = re.compile(r'(?<!\\\\)\\\\(?![\"\\\\/bfnrtu])')  # unescaped backslash not starting a valid escape\n",
        "\n",
        "def _loads_relaxed(s: str):\n",
        "    \"\"\"Try strict JSON; if it fails, patch common issues and try again.\"\"\"\n",
        "    try:\n",
        "        return json.loads(s)\n",
        "    except json.JSONDecodeError:\n",
        "        s2 = BAD_BACKSLASH.sub(r'\\\\\\\\', s)\n",
        "\n",
        "        try:\n",
        "            return json.loads(s2)\n",
        "        except json.JSONDecodeError:\n",
        "            return None\n",
        "\n",
        "def read_jsonl(path: str, show_errors: int = 3) -> List[Tuple[str, str]]:\n",
        "    \"\"\"Robust reader: JSONL or JSON-array; skips malformed lines with minimal repair.\"\"\"\n",
        "    records: List[Tuple[str, str]] = []\n",
        "\n",
        "    # Detect JSON array vs JSONL\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as fpeek:\n",
        "        start = fpeek.read(256).lstrip()\n",
        "        is_array = start.startswith(\"[\")\n",
        "\n",
        "    if is_array:\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            data = json.load(f)\n",
        "        iterable = data\n",
        "        for obj in iterable:\n",
        "            src = (obj.get(\"native word\") or obj.get(\"native_word\") or obj.get(\"native\") or \"\").strip()\n",
        "            tgt = (obj.get(\"english word\") or obj.get(\"english_word\") or obj.get(\"english\") or \"\").strip().lower()\n",
        "            if src and tgt:\n",
        "                records.append((src, tgt))\n",
        "        return records\n",
        "\n",
        "    # JSONL path\n",
        "    bad, shown = 0, 0\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for i, line in enumerate(f, 1):\n",
        "            line = line.strip()\n",
        "            if not line:\n",
        "                continue\n",
        "            obj = _loads_relaxed(line)\n",
        "            if obj is None:\n",
        "                bad += 1\n",
        "                if shown < show_errors:\n",
        "                    print(f\"[warn] Skipping malformed JSON at line {i}: {line[:160]}...\")\n",
        "                    shown += 1\n",
        "                continue\n",
        "            src = (obj.get(\"native word\") or obj.get(\"native_word\") or obj.get(\"native\") or \"\").strip()\n",
        "            tgt = (obj.get(\"english word\") or obj.get(\"english_word\") or obj.get(\"english\") or \"\").strip().lower()\n",
        "            if src and tgt:\n",
        "                records.append((src, tgt))\n",
        "    if bad:\n",
        "        print(f\"[info] Skipped {bad} malformed lines in {os.path.basename(path)}\")\n",
        "    return records\n",
        "\n",
        "def build_vocabs(records: List[Tuple[str, str]], min_freq: int = 1) -> Tuple[\"CharVocab\",\"CharVocab\"]:\n",
        "    src_chars: List[str] = []\n",
        "    tgt_chars: List[str] = []\n",
        "    for src, tgt in records:\n",
        "        src_chars.extend(list(src))\n",
        "        tgt_chars.extend(list(tgt))\n",
        "    src_vocab = CharVocab(src_chars, min_freq=min_freq)\n",
        "    tgt_vocab = CharVocab(tgt_chars, min_freq=min_freq)\n",
        "    return src_vocab, tgt_vocab\n",
        "\n",
        "_SPLIT_MAP = {\"train\":\"train\",\"training\":\"train\",\"validation\":\"valid\",\"val\":\"valid\",\"dev\":\"valid\",\"test\":\"test\"}\n",
        "\n",
        "def load_aksharantar_local(\n",
        "    language: str,\n",
        "    split: str,\n",
        "    base_dir: str = \".\",\n",
        "    max_examples: Optional[int] = None,\n",
        "    shuffle: bool = False,\n",
        "    seed: int = 42,\n",
        ") -> List[Tuple[str, str]]:\n",
        "    split_key = _SPLIT_MAP.get(split.lower(), split.lower())\n",
        "    # Prefer .jsonl, then .json\n",
        "    candidates = [f\"{language}_{split_key}.jsonl\", f\"{language}_{split_key}.json\"]\n",
        "    path = next((os.path.join(base_dir, c) for c in candidates if os.path.isfile(os.path.join(base_dir, c))), None)\n",
        "    if path is None:\n",
        "        raise FileNotFoundError(f\"Missing file for split '{split}': tried {candidates} in {os.path.abspath(base_dir)}\")\n",
        "\n",
        "    records = read_jsonl(path)\n",
        "\n",
        "    if shuffle:\n",
        "        rng = random.Random(seed)\n",
        "        rng.shuffle(records)\n",
        "    if max_examples and max_examples > 0:\n",
        "        records = records[:max_examples]\n",
        "    return records\n",
        "\n",
        "# ---------- Optional: fetch from Hugging Face if file is missing locally ----------\n",
        "\n",
        "def _download_single_file(language: str, target: str) -> Optional[str]:\n",
        "    \"\"\"Try to download {lang}_{target}.jsonl/.json; return local path or None.\"\"\"\n",
        "    for ext in (\"jsonl\", \"json\"):\n",
        "        fname = f\"{language}_{target}.{ext}\"\n",
        "        try:\n",
        "            return hf_hub_download(\n",
        "                repo_id=\"ai4bharat/Aksharantar\",\n",
        "                filename=fname,\n",
        "                repo_type=\"dataset\",\n",
        "            )\n",
        "        except Exception:\n",
        "            continue\n",
        "    return None\n",
        "\n",
        "\n",
        "def _download_from_zip(language: str, target: str) -> Optional[str]:\n",
        "    \"\"\"Fallback: download {lang}.zip and extract the target file; return path or None.\"\"\"\n",
        "    try:\n",
        "        zip_path = hf_hub_download(\n",
        "            repo_id=\"ai4bharat/Aksharantar\",\n",
        "            filename=f\"{language}.zip\",\n",
        "            repo_type=\"dataset\",\n",
        "        )\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "    target_candidates = [f\"{language}_{target}.jsonl\", f\"{language}_{target}.json\"]\n",
        "    with zipfile.ZipFile(zip_path) as zf:\n",
        "        names = set(zf.namelist())\n",
        "        hit = next((n for n in target_candidates if n in names), None)\n",
        "        if not hit:\n",
        "            return None\n",
        "        tempdir = tempfile.mkdtemp(prefix=f\"aksh_{language}_\")\n",
        "        out_path = os.path.join(tempdir, hit)\n",
        "        os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
        "        with zf.open(hit) as src, open(out_path, \"wb\") as dst:\n",
        "            shutil.copyfileobj(src, dst)\n",
        "        return out_path\n",
        "\n",
        "\n",
        "def load_aksharantar(\n",
        "    language: str,\n",
        "    split: str,\n",
        "    base_dir: str = \".\",\n",
        "    max_examples: Optional[int] = None,\n",
        "    shuffle: bool = False,\n",
        "    seed: int = 42,\n",
        ") -> List[Tuple[str, str]]:\n",
        "    \"\"\"\n",
        "    Local-first loader; if missing, fetches from HF (dataset repo).\n",
        "    \"\"\"\n",
        "    target = _SPLIT_MAP.get(split.lower(), split.lower())\n",
        "\n",
        "    # 1) Try local\n",
        "    path = _resolve_local_file(base_dir, language, split)\n",
        "\n",
        "    # 2) Try direct file download ({lang}_{target}.jsonl/.json)\n",
        "    if path is None:\n",
        "        path = _download_single_file(language, target)\n",
        "\n",
        "    # 3) Fallback: try zip and extract\n",
        "    if path is None:\n",
        "        path = _download_from_zip(language, target)\n",
        "\n",
        "    if path is None:\n",
        "        raise FileNotFoundError(\n",
        "            f\"Could not resolve split '{split}' for language '{language}' locally or on HF.\\n\"\n",
        "            f\"Tried: {language}_{target}.jsonl/.json and {language}.zip.\"\n",
        "        )\n",
        "\n",
        "    # Read file\n",
        "    records = read_jsonl(path) if path.endswith(\".jsonl\") else _read_json_as_jsonl(path)\n",
        "\n",
        "    # Shuffle / truncate\n",
        "    if shuffle:\n",
        "        rng = random.Random(seed)\n",
        "        rng.shuffle(records)\n",
        "    if max_examples and max_examples > 0:\n",
        "        records = records[:max_examples]\n",
        "    return records\n"
      ],
      "id": "oUM36gNdeG_H"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl75J39JeG_I"
      },
      "source": [
        "## Training & Evaluation Utilities"
      ],
      "id": "Gl75J39JeG_I"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "4f_xXOQueG_I"
      },
      "outputs": [],
      "source": [
        "def trainepoch(model, dataloader, optimizer, criterion, srcpadidx: int, tgtpadidx: int) -> float:\n",
        "    model.train()\n",
        "    totalloss = 0.0\n",
        "    for src, _, tgtin, tgtout, _ in tqdm(dataloader, desc=\"Train\", leave=False):\n",
        "        optimizer.zero_grad()\n",
        "        srckeypaddingmask = (src == srcpadidx)\n",
        "        tgtkeypaddingmask = (tgtin == tgtpadidx)\n",
        "        logits = model(src, tgtin, srckeypaddingmask, tgtkeypaddingmask)\n",
        "        B, T, V = logits.shape\n",
        "        loss = criterion(logits.view(B * T, V), tgtout.view(B * T))\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        totalloss += loss.item()\n",
        "    return totalloss / max(len(dataloader), 1)\n",
        "\n",
        "\n",
        "def evaluate(model, dataloader, criterion, srcpadidx: int, tgtpadidx: int) -> float:\n",
        "    model.eval()\n",
        "    totalloss = 0.0\n",
        "    count = 0\n",
        "    with torch.no_grad():\n",
        "        for src, _, tgtin, tgtout, _ in tqdm(dataloader, desc=\"Val\", leave=False):\n",
        "            srckeypaddingmask = (src == srcpadidx)\n",
        "            tgtkeypaddingmask = (tgtin == tgtpadidx)\n",
        "            logits = model(src, tgtin, srckeypaddingmask, tgtkeypaddingmask)\n",
        "            B, T, V = logits.shape\n",
        "            loss = criterion(logits.view(B * T, V), tgtout.view(B * T))\n",
        "\n",
        "            # Check if loss is valid before adding\n",
        "            if not torch.isnan(loss) and not torch.isinf(loss):\n",
        "                totalloss += loss.item()\n",
        "                count += 1\n",
        "\n",
        "    # Return average only if we have valid losses\n",
        "    return totalloss / max(count, 1) if count > 0 else float('nan')\n"
      ],
      "id": "4f_xXOQueG_I"
    },
    {
      "cell_type": "code",
      "source": [
        "def subsample_records(records: List[Tuple[str, str]], limit: int = MAX_TRAIN_LIMIT, seed: int = 42) -> List[Tuple[str, str]]:\n",
        "    if limit <= 0 or len(records) <= limit:\n",
        "        return records\n",
        "    limit = min(limit, MAX_TRAIN_LIMIT)\n",
        "    rng = random.Random(seed)\n",
        "    return rng.sample(records, limit)"
      ],
      "metadata": {
        "id": "ri1s8Cc_i3v7"
      },
      "id": "ri1s8Cc_i3v7",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "le1r4_2ZeG_I"
      },
      "source": [
        "## Decoding Helpers"
      ],
      "id": "le1r4_2ZeG_I"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "C_yUDz1GeG_I"
      },
      "outputs": [],
      "source": [
        "def greedy_decode(model: LocalTransformer, src_seq: str, src_vocab: CharVocab, tgt_vocab: CharVocab, max_len: int = 80) -> str:\n",
        "    model.eval()\n",
        "    device = model.device\n",
        "    with torch.no_grad():\n",
        "        src_idxs = src_vocab.encode(src_seq)\n",
        "        if not src_idxs:\n",
        "            return \"\"\n",
        "        src_tensor = torch.tensor([src_idxs], dtype=torch.long, device=device)\n",
        "        src_key_padding_mask = (src_tensor == src_vocab.pad_idx)\n",
        "        memory = model.encode(src_tensor, src_key_padding_mask)\n",
        "\n",
        "        ys = torch.tensor([[tgt_vocab.sos_idx]], dtype=torch.long, device=device)\n",
        "        tgt_key_padding_mask = (ys == tgt_vocab.pad_idx)\n",
        "\n",
        "        output_tokens: List[int] = []\n",
        "        for _ in range(max_len):\n",
        "            logits = model.decode(ys, memory, src_key_padding_mask, tgt_key_padding_mask)\n",
        "            next_token = logits[:, -1, :].argmax(dim=-1).item()\n",
        "            if next_token == tgt_vocab.eos_idx:\n",
        "                break\n",
        "            output_tokens.append(next_token)\n",
        "            ys = torch.cat([ys, torch.tensor([[next_token]], device=device)], dim=1)\n",
        "            tgt_key_padding_mask = (ys == tgt_vocab.pad_idx)\n",
        "        return tgt_vocab.decode(output_tokens)\n",
        "\n",
        "\n",
        "def beam_search_decode(\n",
        "    model: LocalTransformer,\n",
        "    src_seq: str,\n",
        "    src_vocab: CharVocab,\n",
        "    tgt_vocab: CharVocab,\n",
        "    beam_size: int = 3,\n",
        "    max_len: int = 80,\n",
        ") -> str:\n",
        "    model.eval()\n",
        "    device = model.device\n",
        "    with torch.no_grad():\n",
        "        src_idxs = src_vocab.encode(src_seq)\n",
        "        if not src_idxs:\n",
        "            return \"\"\n",
        "        src_tensor = torch.tensor([src_idxs], dtype=torch.long, device=device)\n",
        "        src_key_padding_mask = (src_tensor == src_vocab.pad_idx)\n",
        "        memory = model.encode(src_tensor, src_key_padding_mask)\n",
        "\n",
        "        beams: List[Tuple[float, List[int]]] = [(0.0, [tgt_vocab.sos_idx])]\n",
        "        completed: List[Tuple[float, List[int]]] = []\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            new_beams: List[Tuple[float, List[int]]] = []\n",
        "            for log_prob, seq in beams:\n",
        "                if seq[-1] == tgt_vocab.eos_idx:\n",
        "                    completed.append((log_prob, seq))\n",
        "                    continue\n",
        "                ys = torch.tensor([seq], dtype=torch.long, device=device)\n",
        "                tgt_key_padding_mask = (ys == tgt_vocab.pad_idx)\n",
        "                logits = model.decode(ys, memory, src_key_padding_mask, tgt_key_padding_mask)\n",
        "                log_probs = torch.log_softmax(logits[:, -1, :], dim=-1)\n",
        "                top_logp, top_idx = log_probs.topk(beam_size)\n",
        "                for lp, idx in zip(top_logp[0], top_idx[0]):\n",
        "                    next_seq = seq + [idx.item()]\n",
        "                    new_beams.append((log_prob + lp.item(), next_seq))\n",
        "            if not new_beams:\n",
        "                break\n",
        "            new_beams.sort(key=lambda x: x[0], reverse=True)\n",
        "            beams = new_beams[:beam_size]\n",
        "\n",
        "        if not completed:\n",
        "            completed = beams\n",
        "        best_seq = max(completed, key=lambda x: x[0])[1]\n",
        "        decoded: List[int] = []\n",
        "        for tok in best_seq[1:]:\n",
        "            if tok == tgt_vocab.eos_idx:\n",
        "                break\n",
        "            decoded.append(tok)\n",
        "        return tgt_vocab.decode(decoded)"
      ],
      "id": "C_yUDz1GeG_I"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPUggoxQeG_K"
      },
      "source": [
        "## Training Loop Helper\n",
        "\n",
        "The following cell wraps model creation, DataLoader setup, training, and validation into a reusable helper function."
      ],
      "id": "JPUggoxQeG_K"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "1nQ6Vd-ueG_K"
      },
      "outputs": [],
      "source": [
        "def prepare_dataloaders(\n",
        "    records: List[Tuple[str, str]],\n",
        "    device: torch.device,\n",
        "    batch_size: int = 64,\n",
        "    train_split: float = 0.9,\n",
        ") -> Tuple[DataLoader, Optional[DataLoader], CharVocab, CharVocab]:\n",
        "    random.shuffle(records)\n",
        "    split_idx = int(len(records) * train_split)\n",
        "    train_records = records[:split_idx]\n",
        "    val_records = records[split_idx:] if split_idx < len(records) else []\n",
        "\n",
        "    src_vocab, tgt_vocab = build_vocabs(train_records)\n",
        "\n",
        "    def collate(batch):\n",
        "        return collate_fn(batch, src_vocab, tgt_vocab, device)\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        TransliterationDataset(train_records),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=collate,\n",
        "    )\n",
        "    val_loader = None\n",
        "    if val_records:\n",
        "        val_loader = DataLoader(\n",
        "            TransliterationDataset(val_records),\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            collate_fn=collate,\n",
        "        )\n",
        "    return train_loader, val_loader, src_vocab, tgt_vocab\n",
        "\n",
        "\n",
        "def train_model(\n",
        "    train_loader: DataLoader,\n",
        "    val_loader: Optional[DataLoader],\n",
        "    src_vocab: CharVocab,\n",
        "    tgt_vocab: CharVocab,\n",
        "    device: torch.device,\n",
        "    epochs: int = 5,\n",
        "    lr: float = 3e-4,\n",
        "    config: Optional[TransformerConfig] = None,\n",
        ") -> Tuple[LocalTransformer, Dict[str, List[float]]]:\n",
        "    if config is None:\n",
        "        config = TransformerConfig()\n",
        "\n",
        "    model = LocalTransformer(len(src_vocab), len(tgt_vocab), config, device=device).to(device)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab.pad_idx)\n",
        "\n",
        "    history = {\"train_loss\": [], \"val_loss\": []}\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train_loss = train_epoch(model, train_loader, optimizer, criterion, src_vocab.pad_idx, tgt_vocab.pad_idx)\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "\n",
        "        if val_loader is not None:\n",
        "            val_loss = evaluate(model, val_loader, criterion, src_vocab.pad_idx, tgt_vocab.pad_idx)\n",
        "            history[\"val_loss\"].append(val_loss)\n",
        "            print(f\"Epoch {epoch}: train={train_loss:.4f}, val={val_loss:.4f}\")\n",
        "        else:\n",
        "            print(f\"Epoch {epoch}: train={train_loss:.4f}\")\n",
        "    return model, history"
      ],
      "id": "1nQ6Vd-ueG_K"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "853GMorweG_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e50b09fb-693c-4077-da22-6e73e27cef5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[warn] Skipping malformed JSON at line 276011: {\"unique_identifier\": \"hin276011\", \"native word\": \"समुद्रायायन\", \"english wor...\n",
            "[info] Skipped 1 malformed lines in hin_train.jsonl\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "language = \"hin\"\n",
        "train = load_aksharantar_local(language, \"train\", base_dir=\".\",max_examples=MAX_TRAIN_LIMIT)\n",
        "valid = load_aksharantar_local(language, \"validation\", base_dir=\".\")\n",
        "test  = load_aksharantar_local(language, \"test\", base_dir=\".\")\n",
        "\n",
        "src_vocab, tgt_vocab = build_vocabs(train + valid)"
      ],
      "id": "853GMorweG_L"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "YMEZVT6keG_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37376f25-f0dc-4b80-a08f-74a018a498f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "Train batches: 748 | Val batches: 84\n",
            "Source vocab size: 72 | Target vocab size: 30\n"
          ]
        }
      ],
      "source": [
        "import inspect\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "val_records = valid or []                      # from your previous cell\n",
        "all_records = (train or []) + (val_records)    # for vocab building\n",
        "src_vocab, tgt_vocab = build_vocabs(all_records, min_freq=1)\n",
        "\n",
        "def prepare_dataloaders_compat(prepare_fn, *,\n",
        "                               train_records, val_records,\n",
        "                               src_vocab, tgt_vocab,\n",
        "                               device, batch_size):\n",
        "    \"\"\"Call `prepare_fn` regardless of whether it expects\n",
        "       - (all_records, device, batch_size)  -> returns (train_loader, val_loader[, src_vocab, tgt_vocab])\n",
        "       - (train, val, src_vocab, tgt_vocab, device, batch_size)\n",
        "       - (train, val, device, batch_size)   -> returns vocabs or not\n",
        "    \"\"\"\n",
        "    try:\n",
        "        sig = inspect.signature(prepare_fn)\n",
        "        params = list(sig.parameters.keys())\n",
        "    except Exception:\n",
        "        params = []\n",
        "\n",
        "    # Case A: legacy signature: (all_records, device, batch_size)\n",
        "    if len(params) >= 3 and params[0] not in {\"train_records\", \"train\", \"X_train\"}:\n",
        "        out = prepare_fn(train_records + (val_records or []), device, batch_size)\n",
        "        try:\n",
        "            train_loader, val_loader, sv, tv = out\n",
        "            src, tgt = sv, tv\n",
        "        except ValueError:\n",
        "            train_loader, val_loader = out\n",
        "            src, tgt = src_vocab, tgt_vocab\n",
        "        return train_loader, val_loader, src, tgt\n",
        "\n",
        "    # Case B: expects (train, val, src_vocab, tgt_vocab, device, batch_size)\n",
        "    try:\n",
        "        out = prepare_fn(train_records, (val_records or None), src_vocab, tgt_vocab, device, batch_size)\n",
        "        try:\n",
        "            train_loader, val_loader, sv, tv = out\n",
        "            return train_loader, val_loader, sv, tv\n",
        "        except ValueError:\n",
        "            train_loader, val_loader = out\n",
        "            return train_loader, val_loader, src_vocab, tgt_vocab\n",
        "    except TypeError:\n",
        "        # Case C: (train, val, device, batch_size)\n",
        "        out = prepare_fn(train_records, (val_records or None), device, batch_size)\n",
        "        try:\n",
        "            train_loader, val_loader, sv, tv = out\n",
        "            return train_loader, val_loader, sv, tv\n",
        "        except ValueError:\n",
        "            train_loader, val_loader = out\n",
        "            return train_loader, val_loader, src_vocab, tgt_vocab\n",
        "\n",
        "# ---- use the compat wrapper ----\n",
        "train_loader, val_loader, src_vocab, tgt_vocab = prepare_dataloaders_compat(\n",
        "    prepare_dataloaders,\n",
        "    train_records=train,\n",
        "    val_records=val_records,\n",
        "    src_vocab=src_vocab,\n",
        "    tgt_vocab=tgt_vocab,\n",
        "    device=device,\n",
        "    batch_size=128,\n",
        ")\n",
        "\n",
        "print(f\"Device: {device.type}\")\n",
        "print(f\"Train batches: {len(train_loader) if train_loader else 0} | \"\n",
        "      f\"Val batches: {len(val_loader) if val_loader else 0}\")\n",
        "print(f\"Source vocab size: {len(src_vocab)} | Target vocab size: {len(tgt_vocab)}\")"
      ],
      "id": "YMEZVT6keG_L"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "cVc2RWtgeG_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdeba4a8-4e5e-4d04-d0db-9ac9fbce42d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1:   0%|          | 0/748 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py:6041: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n",
            "Epoch 1: 100%|██████████| 748/748 [00:22<00:00, 33.42it/s, loss=0.6495]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:515: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
            "  output = torch._nested_tensor_from_mask(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train=0.9387, Val=0.5587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████| 748/748 [00:21<00:00, 34.81it/s, loss=0.5947]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: Train=0.5884, Val=0.4776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████| 748/748 [00:21<00:00, 34.91it/s, loss=0.4362]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: Train=0.5157, Val=0.4514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████| 748/748 [00:21<00:00, 34.66it/s, loss=0.4899]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: Train=0.4842, Val=0.4305\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████| 748/748 [00:21<00:00, 34.36it/s, loss=0.4909]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: Train=0.4660, Val=0.4213\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6: 100%|██████████| 748/748 [00:21<00:00, 34.91it/s, loss=0.4340]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: Train=0.4521, Val=0.4191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7: 100%|██████████| 748/748 [00:21<00:00, 35.32it/s, loss=0.4103]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7: Train=0.4412, Val=0.4114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8: 100%|██████████| 748/748 [00:21<00:00, 35.13it/s, loss=0.4033]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8: Train=0.4324, Val=0.4118\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9: 100%|██████████| 748/748 [00:21<00:00, 34.81it/s, loss=0.4567]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9: Train=0.4251, Val=0.4036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 10: 100%|██████████| 748/748 [00:21<00:00, 34.54it/s, loss=0.4084]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10: Train=0.4191, Val=0.4023\n",
            "✅ Training complete!\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_step(model, batch, criterion, optimizer):\n",
        "    model.train()\n",
        "    src, src_len, tgt_in, tgt_out, tgt_len = batch\n",
        "\n",
        "    src_mask = (src == src_vocab.pad_idx)\n",
        "    tgt_mask = (tgt_in == tgt_vocab.pad_idx)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(src, tgt_in, src_mask, tgt_mask)\n",
        "\n",
        "    B, T, V = logits.shape\n",
        "    loss = criterion(logits.view(B * T, V), tgt_out.view(B * T))\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "def evaluate(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            src, src_len, tgt_in, tgt_out, tgt_len = batch\n",
        "            logits = model(src, tgt_in, (src == 0), (tgt_in == 0))\n",
        "\n",
        "            B, T, V = logits.shape\n",
        "            loss = criterion(logits.view(B * T, V), tgt_out.view(B * T))\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "config = TransformerConfig(\n",
        "    d_model=256,\n",
        "    nhead=4,\n",
        "    num_encoder_layers=2,\n",
        "    num_decoder_layers=2,\n",
        "    dim_feedforward=512,\n",
        "    dropout=0.1,\n",
        "    local_window=None  # Use full attention (or set to a number like 10 for local)\n",
        ")\n",
        "\n",
        "# Create model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = LocalTransformer(\n",
        "    src_vocab_size=len(src_vocab),\n",
        "    tgt_vocab_size=len(tgt_vocab),\n",
        "    config=config,\n",
        "    device=device\n",
        ").to(device)\n",
        "\n",
        "# Training loop\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab.pad_idx)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "\n",
        "history = {'train_loss': [], 'val_loss': []}\n",
        "\n",
        "for epoch in range(10):\n",
        "    train_losses = []\n",
        "\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
        "    for batch in pbar:\n",
        "        loss = train_step(model, batch, criterion, optimizer)\n",
        "        train_losses.append(loss)\n",
        "        pbar.set_postfix({'loss': f'{loss:.4f}'})\n",
        "\n",
        "    avg_train_loss = sum(train_losses) / len(train_losses)\n",
        "    val_loss = evaluate(model, val_loader, criterion)\n",
        "\n",
        "    history['train_loss'].append(avg_train_loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}: Train={avg_train_loss:.4f}, Val={val_loss:.4f}\")\n",
        "\n",
        "# Save model\n",
        "torch.save({\n",
        "    'model_state': model.state_dict(),\n",
        "    'config': config.__dict__,\n",
        "    'history': history\n",
        "}, 'transformer_model.pt')\n",
        "\n",
        "print(\"✅ Training complete!\")\n"
      ],
      "id": "cVc2RWtgeG_M"
    },
    {
      "cell_type": "code",
      "source": [
        "def vocab_to_dict(vocab):\n",
        "    \"\"\"Convert CharVocab object to dictionary for saving\"\"\"\n",
        "    return {\n",
        "        'idx2token': list(vocab.idx2token),\n",
        "        'token2idx': dict(vocab.token2idx)\n",
        "    }\n",
        "\n",
        "# Save model with vocabularies included\n",
        "torch.save({\n",
        "    'model_state': model.state_dict(),\n",
        "    'config': config.__dict__,\n",
        "    'src_vocab': vocab_to_dict(src_vocab),\n",
        "    'tgt_vocab': vocab_to_dict(tgt_vocab),\n",
        "    'history': history,\n",
        "}, 'transformer_model.pt')\n",
        "\n",
        "print(\"✅ Model saved with vocabularies!\")\n",
        "print(f\"   File: transformer_model.pt\")\n",
        "print(f\"   Source vocab size: {len(src_vocab)}\")\n",
        "print(f\"   Target vocab size: {len(tgt_vocab)}\")\n",
        "print(f\"   Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLqlZ9M0op0-",
        "outputId": "63e11f06-1bdd-4b7f-cba3-5896e20b99c8"
      },
      "id": "LLqlZ9M0op0-",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model saved with vocabularies!\n",
            "   File: transformer_model.pt\n",
            "   Source vocab size: 72\n",
            "   Target vocab size: 30\n",
            "   Model parameters: 2,669,598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "MXpSYqDYeG_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26da7c8d-6d49-40e5-c6a0-372bea6de5c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: भागना\n",
            "Greedy: bhagana\n",
            "Beam: bhagna\n"
          ]
        }
      ],
      "source": [
        "word = \"भागना\"\n",
        "greedy_output = greedy_decode(model, word, src_vocab, tgt_vocab)\n",
        "beam_output = beam_search_decode(model, word, src_vocab, tgt_vocab, beam_size=10)\n",
        "print(\"Input:\", word)\n",
        "print(\"Greedy:\", greedy_output)\n",
        "print(\"Beam:\", beam_output)"
      ],
      "id": "MXpSYqDYeG_M"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "\n",
        "# -------------------- Metric Functions --------------------\n",
        "\n",
        "def edit_distance(s1, s2):\n",
        "    \"\"\"Compute Levenshtein edit distance between two strings\"\"\"\n",
        "    if len(s1) > len(s2):\n",
        "        s1, s2 = s2, s1\n",
        "\n",
        "    distances = range(len(s1) + 1)\n",
        "    for i2, c2 in enumerate(s2):\n",
        "        distances_ = [i2+1]\n",
        "        for i1, c1 in enumerate(s1):\n",
        "            if c1 == c2:\n",
        "                distances_.append(distances[i1])\n",
        "            else:\n",
        "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
        "        distances = distances_\n",
        "    return distances[-1]\n",
        "\n",
        "def longest_common_subsequence_length(s1, s2):\n",
        "    \"\"\"\n",
        "    Compute LCS length using formula from NEWS 2015 (Eq. 2):\n",
        "    LCS(c, r) = 1/2 * (|c| + |r| - ED(c, r))\n",
        "    \"\"\"\n",
        "    return 0.5 * (len(s1) + len(s2) - edit_distance(s1, s2))\n",
        "\n",
        "def compute_word_accuracy(predictions, references):\n",
        "    \"\"\"\n",
        "    Word Accuracy in Top-1 (ACC) - Section 3.1 of NEWS 2015\n",
        "    Returns the proportion of exact matches between prediction and reference\n",
        "    \"\"\"\n",
        "    correct = 0\n",
        "    for pred, ref in zip(predictions, references):\n",
        "        if pred == ref:\n",
        "            correct += 1\n",
        "    return correct / len(predictions) if predictions else 0.0\n",
        "\n",
        "def compute_character_f1(predictions, references):\n",
        "    \"\"\"\n",
        "    Mean F-score (Character-level) - Section 3.2 of NEWS 2015\n",
        "    Based on longest common subsequence between prediction and reference\n",
        "    \"\"\"\n",
        "    f_scores = []\n",
        "\n",
        "    for pred, ref in zip(predictions, references):\n",
        "        if len(pred) == 0 and len(ref) == 0:\n",
        "            f_scores.append(1.0)\n",
        "            continue\n",
        "        elif len(pred) == 0 or len(ref) == 0:\n",
        "            f_scores.append(0.0)\n",
        "            continue\n",
        "\n",
        "        # Compute LCS length\n",
        "        lcs_len = longest_common_subsequence_length(pred, ref)\n",
        "\n",
        "        # Precision and Recall\n",
        "        precision = lcs_len / len(pred)\n",
        "        recall = lcs_len / len(ref)\n",
        "\n",
        "        # F1 score\n",
        "        if precision + recall > 0:\n",
        "            f1 = 2 * (precision * recall) / (precision + recall)\n",
        "        else:\n",
        "            f1 = 0.0\n",
        "\n",
        "        f_scores.append(f1)\n",
        "\n",
        "    return np.mean(f_scores) if f_scores else 0.0\n",
        "\n",
        "# -------------------- Greedy Decoding --------------------\n",
        "\n",
        "def greedy_decode(model, src, src_vocab, tgt_vocab, device, max_len=50):\n",
        "    \"\"\"\n",
        "    Greedy decoding for transliteration\n",
        "    Returns the predicted transliteration as a string\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        # Encode source\n",
        "        src_mask = (src == src_vocab.pad_idx)\n",
        "        memory = model.encode(src, src_mask)\n",
        "\n",
        "        # Start with SOS token\n",
        "        tgt = torch.LongTensor([[tgt_vocab.sos_idx]]).to(device)\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            tgt_mask = (tgt == tgt_vocab.pad_idx)\n",
        "\n",
        "            # Decode\n",
        "            out = model.decode(tgt, memory, src_mask, tgt_mask)\n",
        "\n",
        "            # Get next token\n",
        "            logits = out[:, -1, :]\n",
        "            next_token = logits.argmax(dim=-1, keepdim=True)\n",
        "\n",
        "            # Stop if EOS\n",
        "            if next_token.item() == tgt_vocab.eos_idx:\n",
        "                break\n",
        "\n",
        "            tgt = torch.cat([tgt, next_token], dim=1)\n",
        "\n",
        "    # Convert to string\n",
        "    tokens = tgt.squeeze(0).cpu().tolist()\n",
        "    chars = [tgt_vocab.idx2token[idx] for idx in tokens\n",
        "             if idx not in [tgt_vocab.pad_idx, tgt_vocab.sos_idx, tgt_vocab.eos_idx]]\n",
        "\n",
        "    return ''.join(chars)\n",
        "\n",
        "# -------------------- Evaluation Function --------------------\n",
        "\n",
        "def evaluate_transliteration(model, dataloader, src_vocab, tgt_vocab, device, dataset_name=\"Dataset\"):\n",
        "    \"\"\"\n",
        "    Evaluate model on a dataset and return metrics\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Evaluating on {dataset_name}\")\n",
        "    print('='*70)\n",
        "    print(\"Generating predictions...\")\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Decoding\"):\n",
        "            src, src_len, tgt_in, tgt_out, tgt_len = batch\n",
        "            batch_size = src.size(0)\n",
        "\n",
        "            # Generate predictions for each example in batch\n",
        "            for i in range(batch_size):\n",
        "                src_i = src[i:i+1]\n",
        "\n",
        "                # Greedy decode\n",
        "                pred = greedy_decode(model, src_i, src_vocab, tgt_vocab, device)\n",
        "                predictions.append(pred)\n",
        "\n",
        "                # Get reference (ground truth)\n",
        "                ref_tokens = tgt_out[i].cpu().tolist()\n",
        "                ref_chars = [tgt_vocab.idx2token[idx] for idx in ref_tokens\n",
        "                           if idx not in [tgt_vocab.pad_idx, tgt_vocab.eos_idx]]\n",
        "                ref = ''.join(ref_chars)\n",
        "                references.append(ref)\n",
        "\n",
        "    # Compute metrics\n",
        "    print(\"\\nComputing metrics...\")\n",
        "    word_acc = compute_word_accuracy(predictions, references)\n",
        "    char_f1 = compute_character_f1(predictions, references)\n",
        "\n",
        "    return word_acc, char_f1, predictions, references\n",
        "\n",
        "# -------------------- Run Evaluation --------------------\n",
        "\n",
        "# Evaluate on validation set\n",
        "val_word_acc, val_char_f1, val_preds, val_refs = evaluate_transliteration(\n",
        "    model, val_loader, src_vocab, tgt_vocab, device, \"Validation Set\"\n",
        ")\n",
        "\n",
        "# Evaluate on test set\n",
        "if 'test_loader' not in globals():\n",
        "    print(\"\\nCreating test loader...\")\n",
        "    test_dataset = TransliterationDataset(test)\n",
        "\n",
        "    def make_collate_fn(src_v, tgt_v, dev):\n",
        "        def collate(batch):\n",
        "            return collate_fn(batch, src_v, tgt_v, dev)\n",
        "        return collate\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=128,\n",
        "        shuffle=False,\n",
        "        collate_fn=make_collate_fn(src_vocab, tgt_vocab, device)\n",
        "    )\n",
        "\n",
        "test_word_acc, test_char_f1, test_preds, test_refs = evaluate_transliteration(\n",
        "    model, test_loader, src_vocab, tgt_vocab, device, \"Test Set\"\n",
        ")\n",
        "\n",
        "# -------------------- Display Results --------------------\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EVALUATION RESULTS\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\n| Dataset       | Word Accuracy | Character F1 |\")\n",
        "print(\"|---------------|---------------|--------------|\")\n",
        "print(f\"| Validation    | {val_word_acc:13.4f} | {val_char_f1:12.4f} |\")\n",
        "print(f\"| Test          | {test_word_acc:13.4f} | {test_char_f1:12.4f} |\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# -------------------- Show Examples --------------------\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"SAMPLE PREDICTIONS (First 10 from test set)\")\n",
        "print(\"=\"*70)\n",
        "print(f\"{'Source':<20} {'Reference':<20} {'Prediction':<20} {'Match':<10}\")\n",
        "print(\"-\"*70)\n",
        "\n",
        "for i in range(min(10, len(test_preds))):\n",
        "    src_word = test[i][0] if i < len(test) else \"N/A\"\n",
        "    ref = test_refs[i]\n",
        "    pred = test_preds[i]\n",
        "    match = \"✓\" if pred == ref else \"✗\"\n",
        "    print(f\"{src_word:<20} {ref:<20} {pred:<20} {match:<10}\")\n",
        "\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Save results dictionary\n",
        "results = {\n",
        "    'validation': {'word_accuracy': val_word_acc, 'character_f1': val_char_f1},\n",
        "    'test': {'word_accuracy': test_word_acc, 'character_f1': test_char_f1},\n",
        "    'predictions': {'val': val_preds, 'test': test_preds},\n",
        "    'references': {'val': val_refs, 'test': test_refs}\n",
        "}\n",
        "\n",
        "print(f\"\\n✅ Evaluation complete!\")\n",
        "print(f\"\\nSummary:\")\n",
        "print(f\"  Validation: {val_word_acc*100:.2f}% accuracy, {val_char_f1:.4f} F1\")\n",
        "print(f\"  Test:       {test_word_acc*100:.2f}% accuracy, {test_char_f1:.4f} F1\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KvczL0IozOs",
        "outputId": "cfaee776-044b-46ed-dceb-3efabea57d2f"
      },
      "id": "6KvczL0IozOs",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "Evaluating on Validation Set\n",
            "======================================================================\n",
            "Generating predictions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Decoding: 100%|██████████| 84/84 [04:42<00:00,  3.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Computing metrics...\n",
            "\n",
            "Creating test loader...\n",
            "\n",
            "======================================================================\n",
            "Evaluating on Test Set\n",
            "======================================================================\n",
            "Generating predictions...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Decoding: 100%|██████████| 79/79 [04:17<00:00,  3.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Computing metrics...\n",
            "\n",
            "======================================================================\n",
            "EVALUATION RESULTS\n",
            "======================================================================\n",
            "\n",
            "| Dataset       | Word Accuracy | Character F1 |\n",
            "|---------------|---------------|--------------|\n",
            "| Validation    |        0.2640 |       0.9073 |\n",
            "| Test          |        0.3507 |       0.9162 |\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "SAMPLE PREDICTIONS (First 10 from test set)\n",
            "======================================================================\n",
            "Source               Reference            Prediction           Match     \n",
            "----------------------------------------------------------------------\n",
            "मैट्रोलॉजिस्ट        maitrologist         matrologist          ✗         \n",
            "पीएचडब्ल्यूसीएस      phwcs                phwcs                ✓         \n",
            "प्रतिद्वन्दियों      pratidwandiyon       pratidwandiyon       ✓         \n",
            "प्रतियुक्ति          pratiyukti           pratiyukti           ✓         \n",
            "एक्सिसटेंस           eksisatens           existens             ✗         \n",
            "फ़िल्मनिर्माता       filmnirmata          filmanirmata         ✗         \n",
            "अद्र्घ               adrgh                adrgh                ✓         \n",
            "लड़ेगे               ladhege              ladege               ✗         \n",
            "एडमिनिस्ट्रेश        administresh         administratio        ✗         \n",
            "शिवालापुरवा          shiwalapurwa         shivalapurva         ✗         \n",
            "======================================================================\n",
            "\n",
            "✅ Evaluation complete!\n",
            "\n",
            "Summary:\n",
            "  Validation: 26.40% accuracy, 0.9073 F1\n",
            "  Test:       35.07% accuracy, 0.9162 F1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------- Metric Functions --------------------\n",
        "\n",
        "def edit_distance(s1, s2):\n",
        "    \"\"\"Compute Levenshtein edit distance between two strings\"\"\"\n",
        "    if len(s1) > len(s2):\n",
        "        s1, s2 = s2, s1\n",
        "\n",
        "    distances = range(len(s1) + 1)\n",
        "    for i2, c2 in enumerate(s2):\n",
        "        distances_ = [i2+1]\n",
        "        for i1, c1 in enumerate(s1):\n",
        "            if c1 == c2:\n",
        "                distances_.append(distances[i1])\n",
        "            else:\n",
        "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
        "        distances = distances_\n",
        "    return distances[-1]\n",
        "\n",
        "def longest_common_subsequence_length(s1, s2):\n",
        "    \"\"\"Compute LCS length using formula from NEWS 2015\"\"\"\n",
        "    return 0.5 * (len(s1) + len(s2) - edit_distance(s1, s2))\n",
        "\n",
        "def compute_precision_recall_f1(pred, ref):\n",
        "    \"\"\"\n",
        "    Compute precision, recall, and F1 for a single prediction\n",
        "    Returns: (precision, recall, f1)\n",
        "    \"\"\"\n",
        "    if len(pred) == 0 and len(ref) == 0:\n",
        "        return 1.0, 1.0, 1.0\n",
        "    elif len(pred) == 0 or len(ref) == 0:\n",
        "        return 0.0, 0.0, 0.0\n",
        "\n",
        "    # Compute LCS length\n",
        "    lcs_len = longest_common_subsequence_length(pred, ref)\n",
        "\n",
        "    # Precision and Recall\n",
        "    precision = lcs_len / len(pred)\n",
        "    recall = lcs_len / len(ref)\n",
        "\n",
        "    # F1 score\n",
        "    if precision + recall > 0:\n",
        "        f1 = 2 * (precision * recall) / (precision + recall)\n",
        "    else:\n",
        "        f1 = 0.0\n",
        "\n",
        "    return precision, recall, f1\n",
        "\n",
        "def compute_word_accuracy(predictions, references):\n",
        "    \"\"\"Word Accuracy in Top-1 (ACC)\"\"\"\n",
        "    correct = 0\n",
        "    for pred, ref in zip(predictions, references):\n",
        "        if pred == ref:\n",
        "            correct += 1\n",
        "    return correct / len(predictions) if predictions else 0.0\n",
        "\n",
        "def compute_metrics(predictions, references):\n",
        "    \"\"\"\n",
        "    Compute all metrics: accuracy, mean precision, mean recall, mean F1\n",
        "    Returns: (accuracy, mean_precision, mean_recall, mean_f1, per_example_metrics)\n",
        "    \"\"\"\n",
        "    precisions = []\n",
        "    recalls = []\n",
        "    f1_scores = []\n",
        "\n",
        "    for pred, ref in zip(predictions, references):\n",
        "        prec, rec, f1 = compute_precision_recall_f1(pred, ref)\n",
        "        precisions.append(prec)\n",
        "        recalls.append(rec)\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "    accuracy = compute_word_accuracy(predictions, references)\n",
        "    mean_precision = np.mean(precisions)\n",
        "    mean_recall = np.mean(recalls)\n",
        "    mean_f1 = np.mean(f1_scores)\n",
        "\n",
        "    per_example = list(zip(precisions, recalls, f1_scores))\n",
        "\n",
        "    return accuracy, mean_precision, mean_recall, mean_f1, per_example\n",
        "\n",
        "# -------------------- Greedy Decoding --------------------\n",
        "\n",
        "def greedy_decode(model, src, src_vocab, tgt_vocab, device, max_len=50):\n",
        "    \"\"\"Greedy decoding for transliteration\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        src_mask = (src == src_vocab.pad_idx)\n",
        "        memory = model.encode(src, src_mask)\n",
        "\n",
        "        tgt = torch.LongTensor([[tgt_vocab.sos_idx]]).to(device)\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            tgt_mask = (tgt == tgt_vocab.pad_idx)\n",
        "            out = model.decode(tgt, memory, src_mask, tgt_mask)\n",
        "            logits = out[:, -1, :]\n",
        "            next_token = logits.argmax(dim=-1, keepdim=True)\n",
        "\n",
        "            if next_token.item() == tgt_vocab.eos_idx:\n",
        "                break\n",
        "\n",
        "            tgt = torch.cat([tgt, next_token], dim=1)\n",
        "\n",
        "    tokens = tgt.squeeze(0).cpu().tolist()\n",
        "    chars = [tgt_vocab.idx2token[idx] for idx in tokens\n",
        "             if idx not in [tgt_vocab.pad_idx, tgt_vocab.sos_idx, tgt_vocab.eos_idx]]\n",
        "\n",
        "    return ''.join(chars)\n",
        "\n",
        "# -------------------- Beam Search Decoding --------------------\n",
        "\n",
        "def beam_search_decode(model, src, src_vocab, tgt_vocab, device, beam_width=5, max_len=50):\n",
        "    \"\"\"\n",
        "    Beam search decoding for transliteration\n",
        "    Returns the best transliteration found\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        src_mask = (src == src_vocab.pad_idx)\n",
        "        memory = model.encode(src, src_mask)\n",
        "\n",
        "        # Initialize beam with SOS token\n",
        "        # Each beam element: (score, sequence)\n",
        "        beams = [(0.0, [tgt_vocab.sos_idx])]\n",
        "        completed = []\n",
        "\n",
        "        for step in range(max_len):\n",
        "            candidates = []\n",
        "\n",
        "            for score, seq in beams:\n",
        "                # Skip if sequence already ended\n",
        "                if seq[-1] == tgt_vocab.eos_idx:\n",
        "                    completed.append((score, seq))\n",
        "                    continue\n",
        "\n",
        "                # Prepare input\n",
        "                tgt = torch.LongTensor([seq]).to(device)\n",
        "                tgt_mask = (tgt == tgt_vocab.pad_idx)\n",
        "\n",
        "                # Decode\n",
        "                out = model.decode(tgt, memory, src_mask, tgt_mask)\n",
        "                logits = out[:, -1, :]\n",
        "                log_probs = torch.log_softmax(logits, dim=-1)\n",
        "\n",
        "                # Get top-k tokens\n",
        "                top_log_probs, top_indices = torch.topk(log_probs, beam_width)\n",
        "\n",
        "                # Add to candidates\n",
        "                for log_prob, token_idx in zip(top_log_probs[0], top_indices[0]):\n",
        "                    new_score = score + log_prob.item()\n",
        "                    new_seq = seq + [token_idx.item()]\n",
        "                    candidates.append((new_score, new_seq))\n",
        "\n",
        "            # Select top beam_width candidates\n",
        "            candidates = sorted(candidates, key=lambda x: x[0], reverse=True)\n",
        "            beams = candidates[:beam_width]\n",
        "\n",
        "            # Check if all beams completed\n",
        "            if all(seq[-1] == tgt_vocab.eos_idx for _, seq in beams):\n",
        "                completed.extend(beams)\n",
        "                break\n",
        "\n",
        "        # Add remaining beams to completed\n",
        "        completed.extend(beams)\n",
        "\n",
        "        # Select best sequence\n",
        "        if not completed:\n",
        "            best_seq = [tgt_vocab.sos_idx, tgt_vocab.eos_idx]\n",
        "        else:\n",
        "            # Normalize by length to avoid bias towards shorter sequences\n",
        "            best_score, best_seq = max(completed, key=lambda x: x[0] / len(x[1]))\n",
        "\n",
        "    # Convert to string\n",
        "    chars = [tgt_vocab.idx2token[idx] for idx in best_seq\n",
        "             if idx not in [tgt_vocab.pad_idx, tgt_vocab.sos_idx, tgt_vocab.eos_idx]]\n",
        "\n",
        "    return ''.join(chars)\n",
        "\n",
        "# -------------------- Evaluation Functions --------------------\n",
        "\n",
        "def evaluate_with_decoding(model, dataloader, src_vocab, tgt_vocab, device,\n",
        "                          decode_fn, dataset_name=\"Dataset\", decode_name=\"Decoding\"):\n",
        "    \"\"\"\n",
        "    Evaluate model with specified decoding strategy\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    references = []\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Evaluating on {dataset_name} using {decode_name}\")\n",
        "    print('='*70)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=f\"{decode_name}\"):\n",
        "            src, src_len, tgt_in, tgt_out, tgt_len = batch\n",
        "            batch_size = src.size(0)\n",
        "\n",
        "            for i in range(batch_size):\n",
        "                src_i = src[i:i+1]\n",
        "\n",
        "                # Decode\n",
        "                pred = decode_fn(model, src_i, src_vocab, tgt_vocab, device)\n",
        "                predictions.append(pred)\n",
        "\n",
        "                # Get reference\n",
        "                ref_tokens = tgt_out[i].cpu().tolist()\n",
        "                ref_chars = [tgt_vocab.idx2token[idx] for idx in ref_tokens\n",
        "                           if idx not in [tgt_vocab.pad_idx, tgt_vocab.eos_idx]]\n",
        "                ref = ''.join(ref_chars)\n",
        "                references.append(ref)\n",
        "\n",
        "    # Compute all metrics\n",
        "    accuracy, mean_prec, mean_rec, mean_f1, per_example = compute_metrics(predictions, references)\n",
        "\n",
        "    return accuracy, mean_prec, mean_rec, mean_f1, per_example, predictions, references\n",
        "\n",
        "# -------------------- Run Evaluations --------------------\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"RUNNING COMPREHENSIVE EVALUATION\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Create test loader if needed\n",
        "if 'test_loader' not in globals():\n",
        "    print(\"\\nCreating test loader...\")\n",
        "    test_dataset = TransliterationDataset(test)\n",
        "\n",
        "    def make_collate_fn(src_v, tgt_v, dev):\n",
        "        def collate(batch):\n",
        "            return collate_fn(batch, src_v, tgt_v, dev)\n",
        "        return collate\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=128,\n",
        "        shuffle=False,\n",
        "        collate_fn=make_collate_fn(src_vocab, tgt_vocab, device)\n",
        "    )\n",
        "\n",
        "# Evaluate with Greedy Decoding\n",
        "print(\"\\n[1/2] Greedy Decoding...\")\n",
        "greedy_acc, greedy_prec, greedy_rec, greedy_f1, greedy_per_ex, greedy_preds, greedy_refs = \\\n",
        "    evaluate_with_decoding(model, test_loader, src_vocab, tgt_vocab, device,\n",
        "                          greedy_decode, \"Test Set\", \"Greedy Decoding\")\n",
        "\n",
        "# Evaluate with Beam Search\n",
        "print(\"\\n[2/2] Beam Search Decoding...\")\n",
        "beam_acc, beam_prec, beam_rec, beam_f1, beam_per_ex, beam_preds, beam_refs = \\\n",
        "    evaluate_with_decoding(model, test_loader, src_vocab, tgt_vocab, device,\n",
        "                          lambda m, s, sv, tv, d: beam_search_decode(m, s, sv, tv, d, beam_width=5),\n",
        "                          \"Test Set\", \"Beam Search (width=5)\")\n",
        "\n",
        "# -------------------- Display Results --------------------\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"EVALUATION RESULTS - COMPARISON\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n### GREEDY DECODING\")\n",
        "print(f\"Top-1 Accuracy (ACC): {greedy_acc:.4f} ({greedy_acc*100:.2f}%)\")\n",
        "print(f\"Mean Precision:       {greedy_prec:.4f}\")\n",
        "print(f\"Mean Recall:          {greedy_rec:.4f}\")\n",
        "print(f\"Mean F1 (Fuzziness):  {greedy_f1:.4f}\")\n",
        "\n",
        "print(\"\\n### BEAM SEARCH DECODING (beam_width=5)\")\n",
        "print(f\"Top-1 Accuracy (ACC): {beam_acc:.4f} ({beam_acc*100:.2f}%)\")\n",
        "print(f\"Mean Precision:       {beam_prec:.4f}\")\n",
        "print(f\"Mean Recall:          {beam_rec:.4f}\")\n",
        "print(f\"Mean F1 (Fuzziness):  {beam_f1:.4f}\")\n",
        "\n",
        "# Comparison table\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COMPARISON TABLE\")\n",
        "print(\"=\"*70)\n",
        "print(\"\\n| Metric           | Greedy Decoding | Beam Search (w=5) | Improvement |\")\n",
        "print(\"|------------------|-----------------|-------------------|-------------|\")\n",
        "print(f\"| Top-1 Accuracy   | {greedy_acc:15.4f} | {beam_acc:17.4f} | {(beam_acc-greedy_acc)*100:10.2f}% |\")\n",
        "print(f\"| Mean Precision   | {greedy_prec:15.4f} | {beam_prec:17.4f} | {(beam_prec-greedy_prec)*100:10.2f}% |\")\n",
        "print(f\"| Mean Recall      | {greedy_rec:15.4f} | {beam_rec:17.4f} | {(beam_rec-greedy_rec)*100:10.2f}% |\")\n",
        "print(f\"| Mean F1          | {greedy_f1:15.4f} | {beam_f1:17.4f} | {(beam_f1-greedy_f1)*100:10.2f}% |\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# -------------------- Analyze Low F1 Examples (BOTH STRATEGIES) --------------------\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"WORDS WITH F1-SCORE < 0.5\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Collect low F1 examples for GREEDY\n",
        "greedy_low_f1 = []\n",
        "for i, (prec, rec, f1) in enumerate(greedy_per_ex):\n",
        "    if f1 < 0.5:\n",
        "        src_word = test[i][0] if i < len(test) else \"N/A\"\n",
        "        ref = greedy_refs[i]\n",
        "        pred = greedy_preds[i]\n",
        "        greedy_low_f1.append((src_word, ref, pred, f1, prec, rec))\n",
        "\n",
        "# Collect low F1 examples for BEAM SEARCH\n",
        "beam_low_f1 = []\n",
        "for i, (prec, rec, f1) in enumerate(beam_per_ex):\n",
        "    if f1 < 0.5:\n",
        "        src_word = test[i][0] if i < len(test) else \"N/A\"\n",
        "        ref = beam_refs[i]\n",
        "        pred = beam_preds[i]\n",
        "        beam_low_f1.append((src_word, ref, pred, f1, prec, rec))\n",
        "\n",
        "print(f\"\\n### GREEDY DECODING\")\n",
        "print(f\"Total examples with F1 < 0.5: {len(greedy_low_f1)} / {len(greedy_refs)} ({len(greedy_low_f1)/len(greedy_refs)*100:.2f}%)\")\n",
        "\n",
        "if greedy_low_f1:\n",
        "    print(f\"\\nShowing first 20 examples:\")\n",
        "    print(f\"\\n{'Source':<20} {'Reference':<20} {'Prediction':<20} {'F1':<8} {'Prec':<8} {'Rec':<8}\")\n",
        "    print(\"-\"*100)\n",
        "\n",
        "    for src, ref, pred, f1, prec, rec in greedy_low_f1[:20]:\n",
        "        print(f\"{src:<20} {ref:<20} {pred:<20} {f1:<8.4f} {prec:<8.4f} {rec:<8.4f}\")\n",
        "else:\n",
        "    print(\"\\n✅ No examples with F1 < 0.5!\")\n",
        "\n",
        "print(f\"\\n### BEAM SEARCH DECODING (beam_width=5)\")\n",
        "print(f\"Total examples with F1 < 0.5: {len(beam_low_f1)} / {len(beam_refs)} ({len(beam_low_f1)/len(beam_refs)*100:.2f}%)\")\n",
        "\n",
        "if beam_low_f1:\n",
        "    print(f\"\\nShowing first 20 examples:\")\n",
        "    print(f\"\\n{'Source':<20} {'Reference':<20} {'Prediction':<20} {'F1':<8} {'Prec':<8} {'Rec':<8}\")\n",
        "    print(\"-\"*100)\n",
        "\n",
        "    for src, ref, pred, f1, prec, rec in beam_low_f1[:20]:\n",
        "        print(f\"{src:<20} {ref:<20} {pred:<20} {f1:<8.4f} {prec:<8.4f} {rec:<8.4f}\")\n",
        "else:\n",
        "    print(\"\\n✅ No examples with F1 < 0.5!\")\n",
        "\n",
        "# -------------------- Compare Low F1 Examples --------------------\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"COMPARISON: Examples where one strategy has F1 < 0.5 but other doesn't\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "# Find examples where greedy fails but beam search succeeds\n",
        "greedy_fails_beam_succeeds = []\n",
        "for i, (g_prec, g_rec, g_f1) in enumerate(greedy_per_ex):\n",
        "    b_prec, b_rec, b_f1 = beam_per_ex[i]\n",
        "    if g_f1 < 0.5 and b_f1 >= 0.5:\n",
        "        src_word = test[i][0] if i < len(test) else \"N/A\"\n",
        "        ref = greedy_refs[i]\n",
        "        greedy_fails_beam_succeeds.append((\n",
        "            src_word, ref, greedy_preds[i], beam_preds[i], g_f1, b_f1\n",
        "        ))\n",
        "\n",
        "# Find examples where beam fails but greedy succeeds\n",
        "beam_fails_greedy_succeeds = []\n",
        "for i, (g_prec, g_rec, g_f1) in enumerate(greedy_per_ex):\n",
        "    b_prec, b_rec, b_f1 = beam_per_ex[i]\n",
        "    if b_f1 < 0.5 and g_f1 >= 0.5:\n",
        "        src_word = test[i][0] if i < len(test) else \"N/A\"\n",
        "        ref = greedy_refs[i]\n",
        "        beam_fails_greedy_succeeds.append((\n",
        "            src_word, ref, greedy_preds[i], beam_preds[i], g_f1, b_f1\n",
        "        ))\n",
        "\n",
        "print(f\"\\n### Greedy fails (F1<0.5) but Beam Search succeeds (F1≥0.5)\")\n",
        "print(f\"Count: {len(greedy_fails_beam_succeeds)}\")\n",
        "\n",
        "if greedy_fails_beam_succeeds:\n",
        "    print(f\"\\nFirst 15 examples:\")\n",
        "    print(f\"\\n{'Source':<15} {'Reference':<15} {'Greedy Pred':<15} {'Beam Pred':<15} {'G-F1':<8} {'B-F1':<8}\")\n",
        "    print(\"-\"*95)\n",
        "\n",
        "    for src, ref, g_pred, b_pred, g_f1, b_f1 in greedy_fails_beam_succeeds[:15]:\n",
        "        print(f\"{src:<15} {ref:<15} {g_pred:<15} {b_pred:<15} {g_f1:<8.4f} {b_f1:<8.4f}\")\n",
        "\n",
        "print(f\"\\n### Beam Search fails (F1<0.5) but Greedy succeeds (F1≥0.5)\")\n",
        "print(f\"Count: {len(beam_fails_greedy_succeeds)}\")\n",
        "\n",
        "if beam_fails_greedy_succeeds:\n",
        "    print(f\"\\nFirst 15 examples:\")\n",
        "    print(f\"\\n{'Source':<15} {'Reference':<15} {'Greedy Pred':<15} {'Beam Pred':<15} {'G-F1':<8} {'B-F1':<8}\")\n",
        "    print(\"-\"*95)\n",
        "\n",
        "    for src, ref, g_pred, b_pred, g_f1, b_f1 in beam_fails_greedy_succeeds[:15]:\n",
        "        print(f\"{src:<15} {ref:<15} {g_pred:<15} {b_pred:<15} {g_f1:<8.4f} {b_f1:<8.4f}\")\n",
        "\n",
        "# -------------------- Both Fail Analysis --------------------\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"WORST CASES: Both strategies fail (F1 < 0.5)\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "both_fail = []\n",
        "for i, (g_prec, g_rec, g_f1) in enumerate(greedy_per_ex):\n",
        "    b_prec, b_rec, b_f1 = beam_per_ex[i]\n",
        "    if g_f1 < 0.5 and b_f1 < 0.5:\n",
        "        src_word = test[i][0] if i < len(test) else \"N/A\"\n",
        "        ref = greedy_refs[i]\n",
        "        both_fail.append((\n",
        "            src_word, ref, greedy_preds[i], beam_preds[i], g_f1, b_f1\n",
        "        ))\n",
        "\n",
        "print(f\"\\nTotal: {len(both_fail)} examples where both strategies have F1 < 0.5\")\n",
        "\n",
        "if both_fail:\n",
        "    # Sort by average F1 to show worst cases first\n",
        "    both_fail_sorted = sorted(both_fail, key=lambda x: (x[4] + x[5]) / 2)\n",
        "\n",
        "    print(f\"\\nWorst 20 examples (sorted by average F1):\")\n",
        "    print(f\"\\n{'Source':<15} {'Reference':<15} {'Greedy Pred':<15} {'Beam Pred':<15} {'G-F1':<8} {'B-F1':<8}\")\n",
        "    print(\"-\"*95)\n",
        "\n",
        "    for src, ref, g_pred, b_pred, g_f1, b_f1 in both_fail_sorted[:20]:\n",
        "        print(f\"{src:<15} {ref:<15} {g_pred:<15} {b_pred:<15} {g_f1:<8.4f} {b_f1:<8.4f}\")\n",
        "\n",
        "# Save detailed results\n",
        "results['low_f1_analysis'] = {\n",
        "    'greedy_low_f1': greedy_low_f1,\n",
        "    'beam_low_f1': beam_low_f1,\n",
        "    'greedy_fails_beam_succeeds': greedy_fails_beam_succeeds,\n",
        "    'beam_fails_greedy_succeeds': beam_fails_greedy_succeeds,\n",
        "    'both_fail': both_fail\n",
        "}\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"✅ Low F1 analysis complete!\")\n",
        "print(\"=\"*70)\n",
        "\n"
      ],
      "metadata": {
        "id": "W-eKQg0GcoT6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ddca00b-6d66-4add-dd41-42b35d388083"
      },
      "id": "W-eKQg0GcoT6",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "RUNNING COMPREHENSIVE EVALUATION\n",
            "======================================================================\n",
            "\n",
            "[1/2] Greedy Decoding...\n",
            "\n",
            "======================================================================\n",
            "Evaluating on Test Set using Greedy Decoding\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Greedy Decoding: 100%|██████████| 79/79 [04:34<00:00,  3.47s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "[2/2] Beam Search Decoding...\n",
            "\n",
            "======================================================================\n",
            "Evaluating on Test Set using Beam Search (width=5)\n",
            "======================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Beam Search (width=5): 100%|██████████| 79/79 [1:10:16<00:00, 53.38s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "EVALUATION RESULTS - COMPARISON\n",
            "======================================================================\n",
            "\n",
            "### GREEDY DECODING\n",
            "Top-1 Accuracy (ACC): 0.3507 (35.07%)\n",
            "Mean Precision:       0.9328\n",
            "Mean Recall:          0.9085\n",
            "Mean F1 (Fuzziness):  0.9162\n",
            "\n",
            "### BEAM SEARCH DECODING (beam_width=5)\n",
            "Top-1 Accuracy (ACC): 0.3518 (35.18%)\n",
            "Mean Precision:       0.9285\n",
            "Mean Recall:          0.9126\n",
            "Mean F1 (Fuzziness):  0.9161\n",
            "\n",
            "======================================================================\n",
            "COMPARISON TABLE\n",
            "======================================================================\n",
            "\n",
            "| Metric           | Greedy Decoding | Beam Search (w=5) | Improvement |\n",
            "|------------------|-----------------|-------------------|-------------|\n",
            "| Top-1 Accuracy   |          0.3507 |            0.3518 |       0.11% |\n",
            "| Mean Precision   |          0.9328 |            0.9285 |      -0.43% |\n",
            "| Mean Recall      |          0.9085 |            0.9126 |       0.41% |\n",
            "| Mean F1          |          0.9162 |            0.9161 |      -0.01% |\n",
            "======================================================================\n",
            "\n",
            "======================================================================\n",
            "WORDS WITH F1-SCORE < 0.5\n",
            "======================================================================\n",
            "\n",
            "### GREEDY DECODING\n",
            "Total examples with F1 < 0.5: 35 / 10112 (0.35%)\n",
            "\n",
            "Showing first 20 examples:\n",
            "\n",
            "Source               Reference            Prediction           F1       Prec     Rec     \n",
            "----------------------------------------------------------------------------------------------------\n",
            "एनसीआरडब्ल्यूसी      enseeaardablyusee    ncrwc                0.3182   0.7000   0.2059  \n",
            "डीडब्ल्यूएन          deedablyuen          dwn                  0.3571   0.8333   0.2273  \n",
            "एचजेडटीसी            echajedateesee       hgdtc                0.4211   0.8000   0.2857  \n",
            "पीडब्ल्यूआईडी        peedablyooaaidee     pwid                 0.3500   0.8750   0.2188  \n",
            "एनडब्ल्यूसी          endablyoosee         nwc                  0.2667   0.6667   0.1667  \n",
            "आईआरपीटीसी           aaeeaarpitisi        irptc                0.4444   0.8000   0.3077  \n",
            "बीआईआईटीएम           beeaaeeaaeeteeem     bitm                 0.3500   0.8750   0.2188  \n",
            "एनडब्ल्यूसी          endablyusee          nwc                  0.2857   0.6667   0.1818  \n",
            "डब्ल्यूपीडी          dablyoopeedee        wpd                  0.3125   0.8333   0.1923  \n",
            "डब्ल्यूएचएल          dablyooechel         whl                  0.3333   0.8333   0.2083  \n",
            "पीडब्ल्यूटी          peedablyootee        pwt                  0.3125   0.8333   0.1923  \n",
            "एनसीआरडब्ल्यूसी      enseeaardablyoosee   ncrwc                0.3043   0.7000   0.1944  \n",
            "डब्ल्यूईएफ           dablyueeef           weff                 0.4286   0.7500   0.3000  \n",
            "एमपीडब्ल्यूपीपीसीएल  empeedablyoopeepeeseeel mpwppl               0.3793   0.9167   0.2391  \n",
            "एमडब्ल्यूपीएल        emdablyupiel         mwpl                 0.4375   0.8750   0.2917  \n",
            "पीएचडब्ल्यूसीएस      peeechdablyuseees    phwcs                0.3636   0.8000   0.2353  \n",
            "डब्ल्यूपीडी          dablyoopidi          wpd                  0.3571   0.8333   0.2273  \n",
            "बीडब्ल्यूटीएस        beedablyooteees      bwts                 0.3684   0.8750   0.2333  \n",
            "ईआरजी                eeaarjee             erg                  0.4545   0.8333   0.3125  \n",
            "क्यूडब्ल्यूवीजीए     kyoodablyooveejeea   qw                   0.1000   0.5000   0.0556  \n",
            "\n",
            "### BEAM SEARCH DECODING (beam_width=5)\n",
            "Total examples with F1 < 0.5: 38 / 10112 (0.38%)\n",
            "\n",
            "Showing first 20 examples:\n",
            "\n",
            "Source               Reference            Prediction           F1       Prec     Rec     \n",
            "----------------------------------------------------------------------------------------------------\n",
            "एनसीआरडब्ल्यूसी      enseeaardablyusee    ncrwc                0.3182   0.7000   0.2059  \n",
            "डीडब्ल्यूएन          deedablyuen          dwn                  0.3571   0.8333   0.2273  \n",
            "एचजेडटीसी            echajedateesee       hgdtc                0.4211   0.8000   0.2857  \n",
            "पीडब्ल्यूआईडी        peedablyooaaidee     pwid                 0.3500   0.8750   0.2188  \n",
            "एनडब्ल्यूसी          endablyoosee         nwc                  0.2667   0.6667   0.1667  \n",
            "क्यूआईडब्ल्यूआई      qiwi                 cuidbluia            0.4615   0.3333   0.7500  \n",
            "आईआरपीटीसी           aaeeaarpitisi        irptc                0.4444   0.8000   0.3077  \n",
            "बीआईआईटीएम           beeaaeeaaeeteeem     bitm                 0.3500   0.8750   0.2188  \n",
            "एनडब्ल्यूसी          endablyusee          nwc                  0.2857   0.6667   0.1818  \n",
            "डब्ल्यूपीडी          dablyoopeedee        wpd                  0.3125   0.8333   0.1923  \n",
            "डब्ल्यूएचएल          dablyooechel         whl                  0.3333   0.8333   0.2083  \n",
            "पीडब्ल्यूटी          peedablyootee        pwt                  0.3125   0.8333   0.1923  \n",
            "एनसीआरडब्ल्यूसी      enseeaardablyoosee   ncrwc                0.3043   0.7000   0.1944  \n",
            "क्यूडब्ल्यूवीजीए     qwvga                cudbluves            0.4286   0.3333   0.6000  \n",
            "डब्ल्यूईएफ           dablyueeef           weff                 0.4286   0.7500   0.3000  \n",
            "एमपीडब्ल्यूपीपीसीएल  empeedablyoopeepeeseeel mpwpp                0.3214   0.9000   0.1957  \n",
            "एमडब्ल्यूपीएल        emdablyupiel         mwpl                 0.4375   0.8750   0.2917  \n",
            "पीएचडब्ल्यूसीएस      peeechdablyuseees    phwcs                0.3636   0.8000   0.2353  \n",
            "डब्ल्यूपीडी          dablyoopidi          wpd                  0.3571   0.8333   0.2273  \n",
            "बीडब्ल्यूटीएस        beedablyooteees      bwts                 0.3684   0.8750   0.2333  \n",
            "\n",
            "======================================================================\n",
            "COMPARISON: Examples where one strategy has F1 < 0.5 but other doesn't\n",
            "======================================================================\n",
            "\n",
            "### Greedy fails (F1<0.5) but Beam Search succeeds (F1≥0.5)\n",
            "Count: 1\n",
            "\n",
            "First 15 examples:\n",
            "\n",
            "Source          Reference       Greedy Pred     Beam Pred       G-F1     B-F1    \n",
            "-----------------------------------------------------------------------------------------------\n",
            "क्यूडब्ल्यूवीजीए kyoodablyooveejeea qw              cudbluves       0.1000   0.5185  \n",
            "\n",
            "### Beam Search fails (F1<0.5) but Greedy succeeds (F1≥0.5)\n",
            "Count: 4\n",
            "\n",
            "First 15 examples:\n",
            "\n",
            "Source          Reference       Greedy Pred     Beam Pred       G-F1     B-F1    \n",
            "-----------------------------------------------------------------------------------------------\n",
            "क्यूआईडब्ल्यूआई qiwi            qidblui         cuidbluia       0.6364   0.4615  \n",
            "क्यूडब्ल्यूवीजीए qwvga           qw              cudbluves       0.5714   0.4286  \n",
            "वाइफाय          vaaiphaay       waifaay         wifie           0.7500   0.4286  \n",
            "वाइज            wise            wige            vaaij           0.8750   0.4444  \n",
            "\n",
            "======================================================================\n",
            "WORST CASES: Both strategies fail (F1 < 0.5)\n",
            "======================================================================\n",
            "\n",
            "Total: 34 examples where both strategies have F1 < 0.5\n",
            "\n",
            "Worst 20 examples (sorted by average F1):\n",
            "\n",
            "Source          Reference       Greedy Pred     Beam Pred       G-F1     B-F1    \n",
            "-----------------------------------------------------------------------------------------------\n",
            "एनडब्ल्यूसी     endablyoosee    nwc             nwc             0.2667   0.2667  \n",
            "एनडब्ल्यूसी     endablyusee     nwc             nwc             0.2857   0.2857  \n",
            "एनसीआरडब्ल्यूसी enseeaardablyoosee ncrwc           ncrwc           0.3043   0.3043  \n",
            "डब्ल्यूपीडी     dablyoopeedee   wpd             wpd             0.3125   0.3125  \n",
            "पीडब्ल्यूटी     peedablyootee   pwt             pwt             0.3125   0.3125  \n",
            "डीडब्ल्यूटी     deedablyootee   dwt             dwt             0.3125   0.3125  \n",
            "आईआरडब्ल्यू     aaiaardablyoo   irw             irw             0.3125   0.3125  \n",
            "एनसीआरडब्ल्यूसी enseeaardablyusee ncrwc           ncrwc           0.3182   0.3182  \n",
            "डब्ल्यूएचएल     dablyooechel    whl             whl             0.3333   0.3333  \n",
            "आईआरडब्ल्यू     aaiaardablyu    irw             irw             0.3333   0.3333  \n",
            "डीडब्ल्यूटी     deedablyutee    dwt             dwt             0.3333   0.3333  \n",
            "डीडब्ल्यूएन     deedablyooen    dwn             dwn             0.3333   0.3333  \n",
            "पीएचडब्ल्यूसीएस peeechdablyooseees phwcs           phwcs           0.3478   0.3478  \n",
            "पीडब्ल्यूआईडी   peedablyooaaidee pwid            pwid            0.3500   0.3500  \n",
            "बीआईआईटीएम      beeaaeeaaeeteeem bitm            bitm            0.3500   0.3500  \n",
            "एमपीडब्ल्यूपीपीसीएल empeedablyoopeepeeseeel mpwppl          mpwpp           0.3793   0.3214  \n",
            "डीडब्ल्यूएन     deedablyuen     dwn             dwn             0.3571   0.3571  \n",
            "डब्ल्यूपीडी     dablyoopidi     wpd             wpd             0.3571   0.3571  \n",
            "डब्ल्यूपीडी     dablyupeedi     wpd             wpd             0.3571   0.3571  \n",
            "पीएचडब्ल्यूसीएस peeechdablyuseees phwcs           phwcs           0.3636   0.3636  \n",
            "\n",
            "======================================================================\n",
            "✅ Low F1 analysis complete!\n",
            "======================================================================\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}